{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet(CVPR 2016), DenseNet 101\n",
    "## ResNet\n",
    "Deep Residual Learning for Image Recognition\n",
    "He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\n",
    "## DenseNet\n",
    "Densely connected convolutional networks.\n",
    "Huang, Gao, et al. \"Densely connected convolutional networks.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.\n",
    "http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.callbacks import *\n",
    "from keras.layers import Input, Dense, Flatten,Activation, BatchNormalization, Conv2D, Conv2DTranspose, MaxPooling2D, Add, AveragePooling2D\n",
    "from keras.activations import *\n",
    "from keras.datasets import cifar,cifar10,cifar100\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=100)\n",
    "y_test  = to_categorical(y_test, num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f071cc9f390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiESRc4vRKL8f7oTu8NG/eWaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f071cd462e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[87])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Residual?\n",
    "Just a error of funtion output. o'_'o   \n",
    "For pretty simple PR reason, we cannot call our net is ErrorNet.   \n",
    ">**It was not OK.**   \n",
    "\n",
    "#### Definition \n",
    "If we have a function $f(x) =b$  \n",
    "Given an apporxination $x_0\\in X$, the *residual* of $f(x)$ is $$b-f(x_0)$$\n",
    "\n",
    "#### Residaul V. Error\n",
    "Error $$x-x_0$$\n",
    "Residual $$f(x)-f(x_0)$$\n",
    "\n",
    "#### How to use it in NN?\n",
    "It's pretty simple. \n",
    "> **Layer is a fucntion** (Roughly)\n",
    "\n",
    "\n",
    "Given we have two mapping of two layers $f,g$, identity function $i$, $H$ is desired mapping of whole block, $F$ is desired mapping of $g\\circ f$. $X$ is a vector space.\n",
    "$$X \\overset{f}{\\longrightarrow} X \\overset{g}{\\longrightarrow} X $$\n",
    "$$x \\longmapsto f(x)  \\longmapsto g\\circ f(x) $$\n",
    "$$i: X\\longrightarrow X$$\n",
    "$$  x \\longmapsto x $$\n",
    "$$H,F: X\\longrightarrow X$$\n",
    "we hope $ g\\circ f$ can be apporched $F$.  \n",
    "  \n",
    "Let $$ H(x) = F(x)+x$$\n",
    "so $$F(x) = H(x)-x$$\n",
    "Given $x_0$ is the apporch value we have.  \n",
    "And the residual of $H$ is $$H(x)-H(x_0)$$  \n",
    "Since\n",
    "$$H(x)= F(x)+x$$\n",
    "$$H(x_0)= F(x_0)+x_0$$\n",
    "we can know that\n",
    "$$ H(x)-H(x_0) = F(x)-F(x_0)+x-x_0$$\n",
    "  \n",
    "Also. If we consider $\\hat{H}, \\hat{F}$ is the mapping we have now.\n",
    "Since\n",
    "$$H(x)= F(x)+x$$\n",
    "$$\\hat{H}(x)=\\hat{F}(x)+x$$\n",
    "so we can get\n",
    "$$H(x)-\\hat{H}(x) = F(x)-\\hat{F}(x)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resdual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 9, 4, 87)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 9, 4, 87)      348         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 9, 4, 87)      0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 9, 4, 87)      68208       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 9, 4, 87)      348         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 9, 4, 87)      0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 9, 4, 87)      68208       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 9, 4, 87)      0           input_1[0][0]                    \n",
      "                                                                   conv2d_2[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 137,112\n",
      "Trainable params: 136,764\n",
      "Non-trainable params: 348\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res_block_input = Input((9,4,87))\n",
    "res_block_1     = BatchNormalization()(res_block_input)\n",
    "res_block_1     = Activation('relu')(res_block_1)\n",
    "res_block_1     = Conv2D(87, 3 , strides=1, padding='same')(res_block_1)\n",
    "res_block_2     = BatchNormalization()(res_block_1)\n",
    "res_block_2     = Activation('relu')(res_block_2)\n",
    "res_block_2     = Conv2D(87, 3 , strides=1, padding='same')(res_block_2)\n",
    "res_block_add   = Add()([res_block_input, res_block_2])\n",
    "\n",
    "res_block = Model(res_block_input, res_block_add, name='res_block')\n",
    "plot_model(res_block, 'resnres_block.png', show_layer_names=False)\n",
    "res_block.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original version ResNet(ReLu+Batch Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### With Resdual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 16, 16, 64)    1792        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 8, 8, 64)      0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 8, 8, 64)      256         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 8, 8, 64)      0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 8, 8, 64)      36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 8, 8, 64)      256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 8, 8, 64)      0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 8, 8, 64)      36928       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 8, 8, 64)      0           max_pooling2d_1[0][0]            \n",
      "                                                                   conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 8, 8, 64)      256         add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 8, 8, 64)      0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 8, 8, 64)      36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 8, 8, 64)      256         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 8, 8, 64)      0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 8, 8, 64)      36928       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 8, 8, 64)      0           add_2[0][0]                      \n",
      "                                                                   conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 8, 8, 64)      256         add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 8, 8, 64)      0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 8, 8, 64)      36928       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 8, 8, 64)      256         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 8, 8, 64)      0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 8, 8, 64)      36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 8, 8, 64)      0           add_3[0][0]                      \n",
      "                                                                   conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 4, 4, 128)     73856       add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 4, 4, 128)     147584      conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 4, 4, 128)     512         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 4, 4, 128)     0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 4, 4, 128)     147584      activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 4, 4, 128)     512         conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 4, 4, 128)     0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 4, 4, 128)     147584      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 4, 4, 128)     0           conv2d_11[0][0]                  \n",
      "                                                                   conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 4, 4, 128)     512         add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 4, 4, 128)     0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 4, 4, 128)     147584      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 4, 4, 128)     512         conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 4, 4, 128)     0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 4, 4, 128)     147584      activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 4, 4, 128)     0           add_5[0][0]                      \n",
      "                                                                   conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 4, 4, 128)     512         add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 4, 4, 128)     0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 4, 4, 128)     147584      activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 4, 4, 128)     512         conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 4, 4, 128)     0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 4, 4, 128)     147584      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 4, 4, 128)     0           add_6[0][0]                      \n",
      "                                                                   conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 2, 2, 128)     0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           51300       flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,386,212\n",
      "Trainable params: 1,383,908\n",
      "Non-trainable params: 2,304\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cl_in      = Input(shape=x_train.shape[1:])\n",
    "cl_conv_1  = Conv2D(64, 3, strides=2, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_in)\n",
    "cl_pl_1    = MaxPooling2D()(cl_conv_1)\n",
    "cl_res_1_1 = BatchNormalization()(cl_pl_1)\n",
    "cl_res_1_1 = Activation('relu')(cl_res_1_1)\n",
    "cl_res_1_1 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_1_1)\n",
    "cl_res_1_2 = BatchNormalization()(cl_res_1_1)\n",
    "cl_res_1_2 = Activation('relu')(cl_res_1_2)\n",
    "cl_res_1_2 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_1_2)\n",
    "cl_res_1_a = Add()([cl_pl_1, cl_res_1_2])\n",
    "cl_res_2_1 = BatchNormalization()(cl_res_1_a)\n",
    "cl_res_2_1 = Activation('relu')(cl_res_2_1)\n",
    "cl_res_2_1 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_2_1)\n",
    "cl_res_2_2 = BatchNormalization()(cl_res_2_1)\n",
    "cl_res_2_2 = Activation('relu')(cl_res_2_2)\n",
    "cl_res_2_2 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_2_2)\n",
    "cl_res_2_a = Add()([cl_res_1_a, cl_res_2_2])\n",
    "cl_res_3_1 = BatchNormalization()(cl_res_2_a)\n",
    "cl_res_3_1 = Activation('relu')(cl_res_3_1)\n",
    "cl_res_3_1 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_3_1)\n",
    "cl_res_3_2 = BatchNormalization()(cl_res_3_1)\n",
    "cl_res_3_2 = Activation('relu')(cl_res_3_2)\n",
    "cl_res_3_2 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_3_2)\n",
    "cl_res_3_a = Add()([cl_res_2_a, cl_res_3_2])\n",
    "cl_conv_2  = Conv2D(128, 3, strides=2, padding='same', kernel_initializer='lecun_normal')(cl_res_3_a)\n",
    "cl_conv_2  = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_conv_2)\n",
    "cl_res_4_1 = BatchNormalization()(cl_conv_2)\n",
    "cl_res_4_1 = Activation('relu')(cl_res_4_1)\n",
    "cl_res_4_1 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_4_1)\n",
    "cl_res_4_2 = BatchNormalization()(cl_res_4_1)\n",
    "cl_res_4_2 = Activation('relu')(cl_res_4_2)\n",
    "cl_res_4_2 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_4_2)\n",
    "cl_res_4_a = Add()([cl_conv_2, cl_res_4_2])\n",
    "cl_res_5_1 = BatchNormalization()(cl_res_4_a)\n",
    "cl_res_5_1 = Activation('relu')(cl_res_5_1)\n",
    "cl_res_5_1 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_5_1)\n",
    "cl_res_5_2 = BatchNormalization()(cl_res_5_1)\n",
    "cl_res_5_2 = Activation('relu')(cl_res_5_2)\n",
    "cl_res_5_2 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_5_2)\n",
    "cl_res_5_a = Add()([cl_res_4_a, cl_res_5_2])\n",
    "cl_res_6_1 = BatchNormalization()(cl_res_5_a)\n",
    "cl_res_6_1 = Activation('relu')(cl_res_6_1)\n",
    "cl_res_6_1 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_6_1)\n",
    "cl_res_6_2 = BatchNormalization()(cl_res_6_1)\n",
    "cl_res_6_2 = Activation('relu')(cl_res_6_2)\n",
    "cl_res_6_2 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_6_2)\n",
    "cl_res_6_a = Add()([cl_res_5_a, cl_res_6_2])\n",
    "cl_pl_2    = AveragePooling2D()(cl_res_6_a)\n",
    "cl_flatten = Flatten()(cl_pl_2)\n",
    "cl_fc100   = Dense(100, activation='softmax')(cl_flatten)\n",
    "classifier_ReLUBN = Model(cl_in, cl_fc100)\n",
    "plot_model(classifier_ReLUBN, 'resnet_ReLUBN.png', show_layer_names=False)\n",
    "classifier_ReLUBN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 12s - loss: 0.2144 - binary_crossentropy: 0.2144 - mean_squared_error: 0.0184 - acc: 0.9804 - val_loss: 0.1982 - val_binary_crossentropy: 0.1982 - val_mean_squared_error: 0.0179 - val_acc: 0.9805\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1934 - binary_crossentropy: 0.1934 - mean_squared_error: 0.0177 - acc: 0.9806 - val_loss: 0.1916 - val_binary_crossentropy: 0.1916 - val_mean_squared_error: 0.0177 - val_acc: 0.9805\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1881 - binary_crossentropy: 0.1881 - mean_squared_error: 0.0173 - acc: 0.9807 - val_loss: 0.1850 - val_binary_crossentropy: 0.1850 - val_mean_squared_error: 0.0171 - val_acc: 0.9808\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1838 - binary_crossentropy: 0.1838 - mean_squared_error: 0.0170 - acc: 0.9809 - val_loss: 0.1846 - val_binary_crossentropy: 0.1846 - val_mean_squared_error: 0.0172 - val_acc: 0.9807\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1815 - binary_crossentropy: 0.1815 - mean_squared_error: 0.0167 - acc: 0.9811 - val_loss: 0.1805 - val_binary_crossentropy: 0.1805 - val_mean_squared_error: 0.0166 - val_acc: 0.9812\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1796 - binary_crossentropy: 0.1796 - mean_squared_error: 0.0165 - acc: 0.9812 - val_loss: 0.1797 - val_binary_crossentropy: 0.1797 - val_mean_squared_error: 0.0166 - val_acc: 0.9811\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1785 - binary_crossentropy: 0.1785 - mean_squared_error: 0.0164 - acc: 0.9813 - val_loss: 0.1783 - val_binary_crossentropy: 0.1783 - val_mean_squared_error: 0.0164 - val_acc: 0.9811\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1770 - binary_crossentropy: 0.1770 - mean_squared_error: 0.0161 - acc: 0.9815 - val_loss: 0.1759 - val_binary_crossentropy: 0.1759 - val_mean_squared_error: 0.0159 - val_acc: 0.9818\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1761 - binary_crossentropy: 0.1761 - mean_squared_error: 0.0160 - acc: 0.9816 - val_loss: 0.1784 - val_binary_crossentropy: 0.1784 - val_mean_squared_error: 0.0164 - val_acc: 0.9813\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 10s - loss: 0.1758 - binary_crossentropy: 0.1758 - mean_squared_error: 0.0159 - acc: 0.9816 - val_loss: 0.1745 - val_binary_crossentropy: 0.1745 - val_mean_squared_error: 0.0156 - val_acc: 0.9820\n",
      "Epoch 11/100\n",
      "20224/50000 [===========>..................] - ETA: 5s - loss: 0.1749 - binary_crossentropy: 0.1749 - mean_squared_error: 0.0157 - acc: 0.9819"
     ]
    }
   ],
   "source": [
    "OPT = Adam(0.00001)\n",
    "classifier_ReLUBN.compile(loss='binary_crossentropy', optimizer=OPT, metrics=['binary_crossentropy', 'mse','acc'])\n",
    "hist_classifier_ReLUBN_Res = classifier_ReLUBN.fit(x_train,y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_classifier_ReLUBN_Res.history['loss'])\n",
    "plt.plot(hist_classifier_ReLUBN_Res.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_classifier_ReLUBN_Res.history['acc'])\n",
    "plt.plot(hist_classifier_ReLUBN_Res.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Resdual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl_in      = Input(shape=x_train.shape[1:])\n",
    "cl_conv_1  = Conv2D(64, 3, strides=2, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_in)\n",
    "cl_pl_1    = MaxPooling2D()(cl_conv_1)\n",
    "cl_res_1_1 = BatchNormalization()(cl_pl_1)\n",
    "cl_res_1_1 = Activation('relu')(cl_res_1_1)\n",
    "cl_res_1_1 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_1_1)\n",
    "cl_res_1_2 = BatchNormalization()(cl_res_1_1)\n",
    "cl_res_1_2 = Activation('relu')(cl_res_1_2)\n",
    "cl_res_1_2 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_1_2)\n",
    "cl_res_2_1 = BatchNormalization()(cl_res_1_2)\n",
    "cl_res_2_1 = Activation('relu')(cl_res_2_1)\n",
    "cl_res_2_1 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_2_1)\n",
    "cl_res_2_2 = BatchNormalization()(cl_res_2_1)\n",
    "cl_res_2_2 = Activation('relu')(cl_res_2_2)\n",
    "cl_res_2_2 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_2_2)\n",
    "cl_res_3_1 = BatchNormalization()(cl_res_2_2)\n",
    "cl_res_3_1 = Activation('relu')(cl_res_3_1)\n",
    "cl_res_3_1 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_3_1)\n",
    "cl_res_3_2 = BatchNormalization()(cl_res_3_1)\n",
    "cl_res_3_2 = Activation('relu')(cl_res_3_2)\n",
    "cl_res_3_2 = Conv2D(64, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_3_2)\n",
    "cl_conv_2  = Conv2D(128, 3, strides=2, padding='same', kernel_initializer='lecun_normal')(cl_res_3_2)\n",
    "cl_conv_2  = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_conv_2)\n",
    "cl_res_4_1 = BatchNormalization()(cl_conv_2)\n",
    "cl_res_4_1 = Activation('relu')(cl_res_4_1)\n",
    "cl_res_4_1 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_4_1)\n",
    "cl_res_4_2 = BatchNormalization()(cl_res_4_1)\n",
    "cl_res_4_2 = Activation('relu')(cl_res_4_2)\n",
    "cl_res_4_2 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_4_2)\n",
    "cl_res_5_1 = BatchNormalization()(cl_res_4_2)\n",
    "cl_res_5_1 = Activation('relu')(cl_res_5_1)\n",
    "cl_res_5_1 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_5_1)\n",
    "cl_res_5_2 = BatchNormalization()(cl_res_5_1)\n",
    "cl_res_5_2 = Activation('relu')(cl_res_5_2)\n",
    "cl_res_5_2 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_5_2)\n",
    "cl_res_6_1 = BatchNormalization()(cl_res_5_2)\n",
    "cl_res_6_1 = Activation('relu')(cl_res_6_1)\n",
    "cl_res_6_1 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_6_1)\n",
    "cl_res_6_2 = BatchNormalization()(cl_res_6_1)\n",
    "cl_res_6_2 = Activation('relu')(cl_res_6_2)\n",
    "cl_res_6_2 = Conv2D(128, 3, strides=1, padding='same', kernel_initializer='lecun_normal')(cl_res_6_2)\n",
    "cl_pl_2    = AveragePooling2D()(cl_res_6_2)\n",
    "cl_flatten = Flatten()(cl_pl_2)\n",
    "cl_fc100   = Dense(100, activation='softmax')(cl_flatten)\n",
    "classifier_ReLUBN_noRes = Model(cl_in, cl_fc100)\n",
    "plot_model(classifier_ReLUBN_noRes, 'classifier_ReLUBN_noRes.png', show_layer_names=False)\n",
    "classifier_ReLUBN_noRes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT = Adam(0.00001)\n",
    "classifier_ReLUBN_noRes.compile(loss='binary_crossentropy', optimizer=OPT, metrics=['binary_crossentropy', 'mse','acc'])\n",
    "hist_classifier_ReLUBN_noRes = classifier_ReLUBN_noRes.fit(\n",
    "    x_train,y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_classifier_ReLUBN_noRes.history['loss'])\n",
    "plt.plot(hist_classifier_ReLUBN_noRes.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_classifier_ReLUBN_noRes.history['acc'])\n",
    "plt.plot(hist_classifier_ReLUBN_noRes.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SeLU version ResNet(No Batch Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### With Resdual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl_in      = Input(shape=x_train.shape[1:])\n",
    "cl_conv_1  = Conv2D(64, 3, strides=2, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_in)\n",
    "cl_pl_1    = MaxPooling2D()(cl_conv_1)\n",
    "cl_res_1_1 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_pl_1)\n",
    "cl_res_1_2 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_1_1)\n",
    "cl_res_1_a = Add()([cl_pl_1, cl_res_1_2])\n",
    "cl_res_2_1 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_1_a)\n",
    "cl_res_2_2 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_2_1)\n",
    "cl_res_2_a = Add()([cl_res_1_a, cl_res_2_2])\n",
    "cl_res_3_1 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_2_a)\n",
    "cl_res_3_2 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_3_1)\n",
    "cl_res_3_a = Add()([cl_res_2_a, cl_res_3_2])\n",
    "cl_conv_2  = Conv2D(128, 3, strides=2, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_3_a)\n",
    "cl_conv_2  = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_conv_2)\n",
    "cl_res_4_1 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_conv_2)\n",
    "cl_res_4_2 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_4_1)\n",
    "cl_res_4_a = Add()([cl_conv_2, cl_res_4_2])\n",
    "cl_res_5_1 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_4_a)\n",
    "cl_res_5_2 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_5_1)\n",
    "cl_res_5_a = Add()([cl_res_4_a, cl_res_5_2])\n",
    "cl_res_6_1 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_5_a)\n",
    "cl_res_6_2 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_6_1)\n",
    "cl_res_6_a = Add()([cl_res_5_a, cl_res_6_2])\n",
    "cl_pl_2    = AveragePooling2D()(cl_res_6_a)\n",
    "cl_flatten = Flatten()(cl_pl_2)\n",
    "cl_fc100   = Dense(100, activation='softmax')(cl_flatten)\n",
    "classifier = Model(cl_in, cl_fc100)\n",
    "plot_model(classifier, 'resnet.png', show_layer_names=False)\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT = Adam(0.00001)\n",
    "classifier.compile(loss='binary_crossentropy', optimizer=OPT, metrics=['binary_crossentropy', 'mse','acc'])\n",
    "hist_ResNet_SELU = classifier.fit(x_train,y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_ResNet_SELU.history['loss'])\n",
    "plt.plot(hist_ResNet_SELU.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_ResNet_SELU.history['acc'])\n",
    "plt.plot(hist_ResNet_SELU.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Resdual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl_in      = Input(shape=x_train.shape[1:])\n",
    "cl_conv_1  = Conv2D(64, 3, strides=2, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_in)\n",
    "cl_pl_1    = MaxPooling2D()(cl_conv_1)\n",
    "cl_res_1_1 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_pl_1)\n",
    "cl_res_1_2 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_1_1)\n",
    "cl_res_2_1 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_1_2)\n",
    "cl_res_2_2 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_2_1)\n",
    "cl_res_3_1 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_2_2)\n",
    "cl_res_3_2 = Conv2D(64, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_3_1)\n",
    "cl_conv_2  = Conv2D(128, 3, strides=2, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_3_2)\n",
    "cl_conv_2  = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_conv_2)\n",
    "cl_res_4_1 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_conv_2)\n",
    "cl_res_4_2 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_4_1)\n",
    "cl_res_5_1 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_4_2)\n",
    "cl_res_5_2 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_5_1)\n",
    "cl_res_6_1 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_5_2)\n",
    "cl_res_6_2 = Conv2D(128, 3, strides=1, activation='selu', padding='same', kernel_initializer='lecun_normal')(cl_res_6_1)\n",
    "cl_pl_2    = AveragePooling2D()(cl_res_6_2)\n",
    "cl_flatten = Flatten()(cl_pl_2)\n",
    "cl_fc100   = Dense(100, activation='softmax')(cl_flatten)\n",
    "classifier_noRes = Model(cl_in, cl_fc100)\n",
    "plot_model(classifier_noRes, 'classifier_noRes.png', show_layer_names=False)\n",
    "classifier_noRes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OPT = Adam(0.00001)\n",
    "classifier_noRes.compile(loss='binary_crossentropy', optimizer=OPT, metrics=['binary_crossentropy', 'mse','acc'])\n",
    "hist_NoResNet_SELU = classifier_noRes.fit(x_train,y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_NoResNet_SELU.history['loss'])\n",
    "plt.plot(hist_NoResNet_SELU.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_NoResNet_SELU.history['acc'])\n",
    "plt.plot(hist_NoResNet_SELU.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_block_input = Input((9,4,87))\n",
    "dense_block_1     = Conv2D(87, 3 , strides=1,name='dense_block_1' , activation='selu', padding='same', kernel_initializer='lecun_normal')(dense_block_input)\n",
    "dense_block_2     = Conv2D(87, 3 , strides=1,name='dense_block_2' , padding='same', activation='selu', kernel_initializer='lecun_normal')(dense_block_1)\n",
    "dense_block_add1  = Add()([dense_block_input, dense_block_2])\n",
    "dense_block_3     = Conv2D(87, 3 , strides=1,name='dense_block_3' , padding='same', activation='selu', kernel_initializer='lecun_normal')(dense_block_add1)\n",
    "dense_block_add2  = Add()([dense_block_input, dense_block_1, dense_block_3])\n",
    "dense_block_4     = Conv2D(87, 3 , strides=1,name='dense_block_4' , padding='same', activation='selu', kernel_initializer='lecun_normal')(dense_block_add2)\n",
    "dense_block_add3  = Add()([dense_block_input, dense_block_1, dense_block_2, dense_block_4])\n",
    "dense_block_5     = Conv2D(87, 3 , strides=1,name='dense_block_5' , padding='same', activation='selu', kernel_initializer='lecun_normal')(dense_block_add3)\n",
    "dense_block_add4  = Add()([dense_block_input, dense_block_1, dense_block_2, dense_block_3, dense_block_5])\n",
    "dense_block_6     = Conv2D(87, 3 , strides=1,name='dense_block_6' , padding='same', activation='selu', kernel_initializer='lecun_normal')(dense_block_add4)\n",
    "dense_block_add5  = Add()([dense_block_input, dense_block_1, dense_block_2, dense_block_3, dense_block_4, dense_block_6])\n",
    "res_block = Model(dense_block_input, dense_block_add5, name='dense_block')\n",
    "plot_model(res_block, 'Dense_block.png')\n",
    "res_block.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
